Developing an Agentic AI Workflow for Voice-Based Flight Ticket Booking

Use Python as the main programming language.

Set up a development environment using Jupyter Notebooks, VS Code, or PyCharm.

Testing:

Write tests for your code using frameworks like pytest.
Ensure your tests cover edge cases and validate the functionality of your solution.
Build a User Interface (Optional):

If applicable, develop a UI using Streamlit or Gradio for interactive testing and demonstrations.


The system should be capable of converting voice commands into actionable tasks, retrieving flight information, and handling the booking process using third-party APIs. Below is a step-by-step guide to help you develop this project.

Define Project Scope and Tasks:

Break down the project into key components:
Voice-to-Text Conversion
Command Interpretation and Processing
Flight Itinerary Retrieval
Booking Confirmation and Execution
Email Notification System
Assign timelines and responsibilities for each component if working in a team.

Voice-to-Text: Google Speech-to-Text, Azure Speech Service, or OpenAI Whisper.
Language Model (LLM): OpenAI’s GPT, LLAMA, or another model that suits the task.
Agentic Framework: AutoGen, CrewAI, LangChain, or similar.
API Integration: Use Python frameworks like Flask to create mock APIs if real APIs are not accessible.
Email Notification: Use Python’s smtplib or a service like SendGrid for sending emails.




Great job! Now that you have successfully captured and converted the user's voice input to text, the next step is to process this text to understand the user's intent and extract relevant details, such as the airline, date, and any other booking-related information.




####we can integrate a simple graphical user interface (GUI) using Tkinter, which is a built-in Python library for creating GUIs. We’ll create buttons to start recording and stop it, then capture the speech, convert it to text, and display the result in the GUI.####




##app.py
from flask import Flask, render_template, request, redirect, url_for, flash, session, jsonify
import sqlite3
import subprocess
import speech_recognition as sr

app = Flask(__name__)
app.secret_key = 'supersecretkey'

# Connect to SQLite database
def get_db():
    conn = sqlite3.connect('users.db')
    return conn

# Route for the login page
@app.route('/', methods=['GET', 'POST'])
def login():
    if request.method == 'POST':
        email_or_username = request.form['email_or_username']
        password = request.form['password']
        
        conn = get_db()
        cursor = conn.cursor()
        cursor.execute("SELECT password FROM users WHERE email=? OR username=?", (email_or_username, email_or_username))
        user = cursor.fetchone()
        
        if user and password == user[0]:  # For simplicity, checking plaintext password
            session['user'] = email_or_username
            return redirect(url_for('index'))
        else:
            flash("Invalid login credentials")
    
    return render_template('login.html')

# Route for the registration page
@app.route('/register', methods=['GET', 'POST'])
def register():
    if request.method == 'POST':
        username = request.form['username']
        email = request.form['email']
        password = request.form['password']  # Use hashing in production
        
        conn = get_db()
        cursor = conn.cursor()
        cursor.execute("INSERT INTO users (username, email, password) VALUES (?, ?, ?)", (username, email, password))
        conn.commit()
        flash("Registration successful! Please log in.")
        return redirect(url_for('login'))

    return render_template('register.html')

# Route for the main page after login
@app.route('/index')
def index():
    if 'user' not in session:
        return redirect(url_for('login'))
    return render_template('index.html')

# Route to handle speech recognition
@app.route('/start_speech', methods=['POST'])
def start_speech():
    recognizer = sr.Recognizer()

    with sr.Microphone() as source:
        recognizer.adjust_for_ambient_noise(source)
        print("Listening...")
        audio = recognizer.listen(source)

        try:
            text = recognizer.recognize_google(audio)
            return jsonify({"transcription": text})
        except sr.UnknownValueError:
            return jsonify({"transcription": "Sorry, I could not understand the audio."})
        except sr.RequestError as e:
            return jsonify({"transcription": f"Error: {e}"})

# Route to logout
@app.route('/logout')
def logout():
    session.pop('user', None)
    return redirect(url_for('login'))

if __name__ == '__main__':
    app.run(debug=True)


index.html

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Speech Recognition</title>
</head>
<body>
    <h1>Welcome, {{ session['user'] }}!</h1>
    <h2>Speech to Text</h2>
    <button id="start-speech-btn">Start to Speak</button>

    <p id="transcription">Your speech will appear here...</p>

    <script>
        const button = document.getElementById('start-speech-btn');
        const transcriptionEl = document.getElementById('transcription');

        button.addEventListener('click', () => {
            fetch('/start_speech', {
                method: 'POST'
            })
            .then(response => response.json())
            .then(data => {
                transcriptionEl.textContent = data.transcription;
            })
            .catch(error => {
                console.error('Error:', error);
                transcriptionEl.textContent = 'Error starting speech recognition.';
            });
        });
    </script>
</body>
</html>
